{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from Kick import kick2gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.dropout1 = nn.Dropout2d(p=0.25)\n",
    "        self.dropout2 = nn.Dropout2d(p=0.5)\n",
    "        self.fc1 = nn.Linear(in_features=64*12*12, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])), batch_size=10, shuffle=True)\n",
    "dataiter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> initialize\n"
     ]
    }
   ],
   "source": [
    "@kick2gpu\n",
    "def run():\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(\"loss at epoch\", batch_idx, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  torch.optim found\n",
      ">>  torchvision found\n",
      ">>  torch.nn found\n",
      ">>  torch.nn.functional found\n",
      ">>  numpy found\n",
      ">>  torch found\n",
      "b'loss at epoch 0 2.2899022102355957'\n",
      "b'loss at epoch 10 2.262838125228882'\n",
      "b'loss at epoch 20 2.3278121948242188'\n",
      "b'loss at epoch 30 2.373546600341797'\n",
      "b'loss at epoch 40 2.2993247509002686'\n",
      "b'loss at epoch 50 2.3009605407714844'\n",
      "b'loss at epoch 60 2.3721916675567627'\n",
      "b'loss at epoch 70 2.2717480659484863'\n",
      "b'loss at epoch 80 2.273516893386841'\n",
      "b'loss at epoch 90 2.2721245288848877'\n",
      "b'loss at epoch 100 2.2755868434906006'\n",
      "b'loss at epoch 110 2.2977397441864014'\n",
      "b'loss at epoch 120 2.2520251274108887'\n",
      "b'loss at epoch 130 2.2681915760040283'\n",
      "b'loss at epoch 140 2.248382091522217'\n",
      "b'loss at epoch 150 2.2398502826690674'\n",
      "b'loss at epoch 160 2.280900716781616'\n",
      "b'loss at epoch 170 2.284872531890869'\n",
      "b'loss at epoch 180 2.2812535762786865'\n",
      "b'loss at epoch 190 2.307100296020508'\n",
      "b'loss at epoch 200 2.2640795707702637'\n",
      "b'loss at epoch 210 2.260305881500244'\n",
      "b'loss at epoch 220 2.2749459743499756'\n",
      "b'loss at epoch 230 2.2676405906677246'\n",
      "b'loss at epoch 240 2.273306369781494'\n",
      "b'loss at epoch 250 2.145078420639038'\n",
      "b'loss at epoch 260 2.1524665355682373'\n",
      "b'loss at epoch 270 2.1640403270721436'\n",
      "b'loss at epoch 280 2.2683749198913574'\n",
      "b'loss at epoch 290 2.204674482345581'\n",
      "b'loss at epoch 300 2.2435507774353027'\n",
      "b'loss at epoch 310 2.2372019290924072'\n",
      "b'loss at epoch 320 2.1899681091308594'\n",
      "b'loss at epoch 330 2.2713229656219482'\n",
      "b'loss at epoch 340 2.1302857398986816'\n",
      "b'loss at epoch 350 2.16972279548645'\n",
      "b'loss at epoch 360 2.2136034965515137'\n",
      "b'loss at epoch 370 2.2044358253479004'\n",
      "b'loss at epoch 380 2.2130415439605713'\n",
      "b'loss at epoch 390 2.248781204223633'\n",
      "b'loss at epoch 400 2.074476718902588'\n",
      "b'loss at epoch 410 2.1707406044006348'\n",
      "b'loss at epoch 420 2.1836295127868652'\n",
      "b'loss at epoch 430 2.120260715484619'\n",
      "b'loss at epoch 440 2.168649196624756'\n",
      "b'loss at epoch 450 2.1720361709594727'\n",
      "b'loss at epoch 460 2.233607769012451'\n",
      "b'loss at epoch 470 2.1768839359283447'\n",
      "b'loss at epoch 480 2.271453380584717'\n",
      "b'loss at epoch 490 2.15250825881958'\n",
      "b'loss at epoch 500 2.0951602458953857'\n",
      "b'loss at epoch 510 2.130394458770752'\n",
      "b'loss at epoch 520 2.0271410942077637'\n",
      "b'loss at epoch 530 2.1519675254821777'\n",
      "b'loss at epoch 540 2.088059425354004'\n",
      "b'loss at epoch 550 2.177511692047119'\n",
      "b'loss at epoch 560 2.121314525604248'\n",
      "b'loss at epoch 570 2.111224889755249'\n",
      "b'loss at epoch 580 2.244262456893921'\n",
      "b'loss at epoch 590 2.1685378551483154'\n",
      "b'loss at epoch 600 2.0724399089813232'\n",
      "b'loss at epoch 610 2.0046212673187256'\n",
      "b'loss at epoch 620 2.1330456733703613'\n",
      "b'loss at epoch 630 2.1786906719207764'\n",
      "b'loss at epoch 640 2.089890480041504'\n",
      "b'loss at epoch 650 2.109574794769287'\n",
      "b'loss at epoch 660 2.087768316268921'\n",
      "b'loss at epoch 670 2.091815948486328'\n",
      "b'loss at epoch 680 2.094679117202759'\n",
      "b'loss at epoch 690 2.1060843467712402'\n",
      "b'loss at epoch 700 2.130023956298828'\n",
      "b'loss at epoch 710 1.8901126384735107'\n",
      "b'loss at epoch 720 2.151606321334839'\n",
      "b'loss at epoch 730 2.1502647399902344'\n",
      "b'loss at epoch 740 1.9815282821655273'\n",
      "b'loss at epoch 750 1.9465949535369873'\n",
      "b'loss at epoch 760 1.9692054986953735'\n",
      "b'loss at epoch 770 2.041109800338745'\n",
      "b'loss at epoch 780 2.019923686981201'\n",
      "b'loss at epoch 790 2.0136306285858154'\n",
      "b'loss at epoch 800 2.1031155586242676'\n",
      "b'loss at epoch 810 1.9710909128189087'\n",
      "b'loss at epoch 820 1.9662349224090576'\n",
      "b'loss at epoch 830 2.046818256378174'\n",
      "b'loss at epoch 840 2.0148143768310547'\n",
      "b'loss at epoch 850 2.0132980346679688'\n",
      "b'loss at epoch 860 1.9700965881347656'\n",
      "b'loss at epoch 870 1.989699125289917'\n",
      "b'loss at epoch 880 1.9920326471328735'\n",
      "b'loss at epoch 890 2.026907444000244'\n",
      "b'loss at epoch 900 2.0376431941986084'\n",
      "b'loss at epoch 910 1.9448623657226562'\n",
      "b'loss at epoch 920 1.867629051208496'\n",
      "b'loss at epoch 930 2.0198616981506348'\n",
      "b'loss at epoch 940 2.0423226356506348'\n",
      "b'loss at epoch 950 1.861403465270996'\n",
      "b'loss at epoch 960 2.0336697101593018'\n",
      "b'loss at epoch 970 1.923829436302185'\n",
      "b'loss at epoch 980 1.8356977701187134'\n",
      "b'loss at epoch 990 1.8170697689056396'\n",
      "b'None'\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
